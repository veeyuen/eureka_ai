{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc31ac65-bd58-4ea4-a78b-39de16aa1a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Step 1: Set up environment & API key securely\n",
    "# You can either store the Perplexity key in an environment variable,\n",
    "# or replace os.getenv(\"PERPLEXITY_API_KEY\") with the key string directly.\n",
    "API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "# Base endpoint for Perplexity's chat completions API\n",
    "API_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "# Define a system‑level instruction that restricts allowed topics\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a specialized research AI assistant who only answers \"\n",
    "    \"questions related to business, markets, finance, or economics. \"\n",
    "    \"If a user asks about an unrelated topic, politely decline.\"\n",
    ")\n",
    "\n",
    "def ask_perplexity(question: str):\n",
    "    \"\"\"\n",
    "    Sends a query to the Perplexity Sonar API with a controlled system prompt.\n",
    "    Returns the model's text reply.\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",  # You can use sonar-small / sonar-medium depending on plan\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        # Optional tuning:\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 800\n",
    "    }\n",
    "\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# Example use\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"What are the latest trends in global bond yields?\"\n",
    "    result = ask_perplexity(query)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca81fa0-43fc-4db7-b846-be51122bddda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# --- API Keys ---\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")  # Get one from serpapi.com\n",
    "\n",
    "# --- API URLs ---\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "SERPAPI_URL = \"https://serpapi.com/search\"\n",
    "\n",
    "# --- Controlled System Prompt ---\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are an intelligent financial research assistant. \"\n",
    "    \"Only answer questions related to markets, finance, or economics. \"\n",
    "    \"Use the live search context below to ensure data accuracy.\"\n",
    ")\n",
    "\n",
    "def fetch_web_context(query: str, num_results: int = 3):\n",
    "    \"\"\"\n",
    "    Retrieve live search results related to the query from SerpAPI.\n",
    "    Returns a combined string containing top summaries and URLs.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"api_key\": SERPAPI_KEY,\n",
    "        \"num\": num_results,\n",
    "    }\n",
    "    resp = requests.get(SERPAPI_URL, params=params)\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    snippets = []\n",
    "    if \"organic_results\" in data:\n",
    "        for item in data[\"organic_results\"][:num_results]:\n",
    "            title = item.get(\"title\", \"\")\n",
    "            snippet = item.get(\"snippet\", \"\")\n",
    "            link = item.get(\"link\", \"\")\n",
    "            snippets.append(f\"{title} — {snippet} ({link})\")\n",
    "\n",
    "    return \"\\n\".join(snippets)\n",
    "\n",
    "\n",
    "def ask_perplexity_with_live_context(question: str):\n",
    "    \"\"\"\n",
    "    Adds current web research context to the system prompt\n",
    "    before sending the query to the Perplexity API.\n",
    "    \"\"\"\n",
    "    # Step 2 → Fetch the latest contextual information\n",
    "    web_context = fetch_web_context(question)\n",
    "\n",
    "    # Compose full prompt payload\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\\n\\nContext:\\n{web_context}\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "    return data[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# --- Example use ---\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"How are global inflation forecasts changing as of October 2025?\"\n",
    "    output = ask_perplexity_with_live_context(query)\n",
    "    print(\"\\n=== ASSISTANT RESPONSE ===\\n\")\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143b827-c010-4f93-9d37-b94714b57e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from transformers import pipeline\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a research AI assistant focused only on markets, \"\n",
    "    \"finance, business, and economics topics. Decline unrelated questions.\"\n",
    ")\n",
    "\n",
    "# ---------- DOMAIN CLASSIFIER ----------\n",
    "# Step 3 domain filter: use a zero-shot classifier to decide\n",
    "# if the query belongs to financial or business context\n",
    "domain_classifier = pipeline(\n",
    "    \"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "\n",
    "ALLOWED_TOPICS = [\n",
    "    \"finance\",\n",
    "    \"economics\",\n",
    "    \"business\",\n",
    "    \"investment\",\n",
    "    \"stock market\",\n",
    "    \"macroeconomics\",\n",
    "    \"corporate strategy\",\n",
    "    \"markets\",\n",
    "    \"financial regulation\"\n",
    "]\n",
    "\n",
    "\n",
    "def is_financial_query(question: str, threshold: float = 0.65) -> bool:\n",
    "    \"\"\"Return True if the question matches allowed financial/economic classes.\"\"\"\n",
    "    result = domain_classifier(question, ALLOWED_TOPICS)\n",
    "    label, score = result[\"labels\"][0], result[\"scores\"][0]\n",
    "    print(f\"Detected domain: {label} (score={score:.2f})\")\n",
    "    return score >= threshold\n",
    "\n",
    "\n",
    "# ---------- PERPLEXITY CALL ----------\n",
    "def query_perplexity(question: str):\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    data = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        \"temperature\": 0.6,\n",
    "        \"max_tokens\": 700\n",
    "    }\n",
    "\n",
    "    response = requests.post(PERPLEXITY_URL, headers=headers, json=data)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "# ---------- MAIN GATEWAY ----------\n",
    "def financial_assistant(question: str):\n",
    "    if not is_financial_query(question):\n",
    "        return (\n",
    "            \"I'm a research assistant specialized in markets, finance, \"\n",
    "            \"and economics only. Your question appears unrelated.\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d796d3-2167-40b6-b28b-067680645aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# AI Financial Research Assistant (Steps 1–5)\n",
    "# ------------------------------\n",
    "import os\n",
    "import requests\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "\n",
    "# ===== STEP 1: Base model setup (Perplexity Sonar API) =====\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a financial research assistant that provides up‑to‑date, \"\n",
    "    \"fact‑checked insights strictly related to markets, finance, \"\n",
    "    \"and economics. Decline questions outside this scope.\"\n",
    ")\n",
    "\n",
    "# ===== STEP 2: Live web context retrieval (SerpAPI or similar) =====\n",
    "SERPAPI_URL = \"https://serpapi.com/search\"\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
    "\n",
    "def get_live_context(query: str, n: int = 3) -> str:\n",
    "    \"\"\"Retrieve fresh context from the web using SerpAPI.\"\"\"\n",
    "    if not SERPAPI_KEY:\n",
    "        return \"No live context (SerpAPI key missing).\"\n",
    "    params = {\"q\": query, \"api_key\": SERPAPI_KEY, \"num\": n}\n",
    "    try:\n",
    "        resp = requests.get(SERPAPI_URL, params=params, timeout=10)\n",
    "        data = resp.json().get(\"organic_results\", [])\n",
    "        results = [f\"{r.get('title','')}: {r.get('snippet','')} ({r.get('link','')})\"\n",
    "                   for r in data[:n]]\n",
    "        return \"\\n\".join(results)\n",
    "    except Exception as e:\n",
    "        return f\"Error getting context: {e}\"\n",
    "\n",
    "# ===== STEP 3: Domain classifier (gatekeeper) =====\n",
    "domain_classifier = pipeline(\"zero-shot-classification\",\n",
    "                             model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "FINANCE_TOPICS = [\n",
    "    \"finance\", \"economics\", \"markets\", \"investing\",\n",
    "    \"macroeconomics\", \"business\", \"corporate strategy\"\n",
    "]\n",
    "\n",
    "def is_finance_query(query: str, threshold: float = 0.65) -> bool:\n",
    "    \"\"\"Checks if user query fits finance/economic categories.\"\"\"\n",
    "    res = domain_classifier(query, FINANCE_TOPICS)\n",
    "    label, score = res[\"labels\"][0], res[\"scores\"][0]\n",
    "    return score >= threshold\n",
    "\n",
    "# ===== STEP 4: Query Perplexity with contextual web data =====\n",
    "def ask_perplexity(question: str, context: str = \"\") -> str:\n",
    "    \"\"\"Send the composed request to Perplexity Sonar API.\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\\n\\nLatest context:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ],\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ===== STEP 5: Streamlit dashboard interface =====\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"AI Financial Research Assistant\", layout=\"wide\")\n",
    "    st.title(\"📊 AI Financial Research Assistant (Powered by Perplexity Sonar)\")\n",
    "\n",
    "    st.sidebar.header(\"Configuration\")\n",
    "    enable_live = st.sidebar.checkbox(\"Enable Live Web Search (SerpAPI)\", value=True)\n",
    "    strict_mode = st.sidebar.slider(\"Finance Domain Strictness\", 0.5, 0.9, 0.65)\n",
    "\n",
    "    query = st.text_input(\"Enter your question about markets, finance, or economics:\")\n",
    "\n",
    "    if st.button(\"Analyze\") and query:\n",
    "        with st.spinner(\"Processing...\"):\n",
    "            if not is_finance_query(query, strict_mode):\n",
    "                st.warning(\"This question does not appear financial/economic in nature.\")\n",
    "                return\n",
    "\n",
    "            context = get_live_context(query, n=3) if enable_live else \"\"\n",
    "            answer = ask_perplexity(query, context)\n",
    "            \n",
    "            st.subheader(\"Perplexity Response:\")\n",
    "            st.write(answer)\n",
    "\n",
    "            st.subheader(\"Live Context (Recent Sources):\")\n",
    "            st.text(context)\n",
    "\n",
    "# ----- Run the dashboard -----\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60816fb1-f64f-4dbe-a6ab-0332d837588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "\n",
    "# ===== Step 1: Base LLM configuration =====\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "# Define a structured JSON output format for responses\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Answer strictly in this JSON format:\n",
    "\n",
    "{\n",
    "  \"summary\": \"<brief summary of the topic>\",\n",
    "  \"key_metrics\": {\n",
    "    \"gdp_growth\": \"<value>\",\n",
    "    \"inflation_rate\": \"<value>\",\n",
    "    \"unemployment_rate\": \"<value>\"\n",
    "  },\n",
    "  \"sources\": [\"<URL 1>\", \"<URL 2>\", ...]\n",
    "}\n",
    "\n",
    "Provide no explanation outside the JSON.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You only answer questions related to finance, markets, or economics.\\n\"\n",
    "    \"Return your answer exactly as the JSON template below:\\n\"\n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# ===== Step 2: Live web search context (example using SerpAPI) =====\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
    "SERPAPI_URL = \"https://serpapi.com/search\"\n",
    "\n",
    "def get_live_context(query:str, num_results:int=3) -> str:\n",
    "    if not SERPAPI_KEY:\n",
    "        return \"Live search disabled: missing SERPAPI_KEY.\"\n",
    "    try:\n",
    "        params = {\"q\": query, \"api_key\": SERPAPI_KEY, \"num\": num_results}\n",
    "        resp = requests.get(SERPAPI_URL, params=params, timeout=10)\n",
    "        resp.raise_for_status()\n",
    "        results = resp.json().get(\"organic_results\", [])\n",
    "        snippets = []\n",
    "        for r in results[:num_results]:\n",
    "            title = r.get(\"title\", \"\")\n",
    "            snippet = r.get(\"snippet\", \"\")\n",
    "            link = r.get(\"link\", \"\")\n",
    "            snippets.append(f\"{title} — {snippet} ({link})\")\n",
    "        return \"\\n\".join(snippets)\n",
    "    except Exception as e:\n",
    "        return f\"Failed to fetch live context: {e}\"\n",
    "\n",
    "# ===== Step 3: Domain filter to restrict to finance =====\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "ALLOWED_TOPICS = [\n",
    "    \"finance\", \"markets\", \"economics\", \"investment\", \n",
    "    \"macroeconomics\", \"business\", \"financial regulation\"\n",
    "]\n",
    "\n",
    "def is_finance_query(query:str, threshold:float=0.65) -> bool:\n",
    "    result = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    label, score = result[\"labels\"][0], result[\"scores\"][0]\n",
    "    return score >= threshold\n",
    "\n",
    "# ===== Step 4: Query Perplexity API with context & formatting =====\n",
    "def ask_perplexity(query:str, context:str=\"\") -> str:\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    system_content = f\"{SYSTEM_PROMPT}\\n\\nLatest context:\\n{context}\"\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": system_content},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 1000\n",
    "    }\n",
    "    response = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ===== Step 5: Streamlit Dashboard =====\n",
    "def main():\n",
    "    st.title(\"AI Financial Research Assistant Dashboard\")\n",
    "    st.markdown(\"Enter finance, markets, or economics questions. Responses are structured JSON.\")\n",
    "\n",
    "    query = st.text_input(\"Your Question:\")\n",
    "    enable_live_search = st.checkbox(\"Enable live web search context\", value=True)\n",
    "\n",
    "    if st.button(\"Get Answer\") and query:\n",
    "        if not is_finance_query(query):\n",
    "            st.error(\"Query filtered out: not related to finance or economics.\")\n",
    "            return\n",
    "\n",
    "        context = get_live_context(query) if enable_live_search else \"\"\n",
    "        with st.spinner(\"Getting response from Perplexity...\"):\n",
    "            response = ask_perplexity(query, context)\n",
    "\n",
    "        st.subheader(\"Response (JSON format):\")\n",
    "        st.code(response, language=\"json\")\n",
    "\n",
    "        if context:\n",
    "            st.subheader(\"Live Web Context Used:\")\n",
    "            st.text(context)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0018d22-9f25-40dc-b6c5-cf6e526de8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "\n",
    "def render_dashboard(response_text):\n",
    "    \"\"\"Render a consistent dashboard layout based on JSON structure.\"\"\"\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        st.error(\"Response not in valid JSON; showing raw text:\")\n",
    "        st.text(response_text)\n",
    "        return\n",
    "\n",
    "    # --- Section 1: Summary ---\n",
    "    st.header(\"Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary available.\"))\n",
    "\n",
    "    # --- Section 2: Key Insights ---\n",
    "    st.subheader(\"Key Insights\")\n",
    "    for item in data.get(\"key_insights\", []):\n",
    "        st.markdown(f\"- {item}\")\n",
    "\n",
    "    # --- Section 3: Key Metrics ---\n",
    "    st.subheader(\"Economic Metrics\")\n",
    "    metrics = data.get(\"metrics\", {})\n",
    "    cols = st.columns(len(metrics))\n",
    "    for i, (key, val) in enumerate(metrics.items()):\n",
    "        cols[i].metric(key, val)\n",
    "\n",
    "    # --- Section 4: Visualization ---\n",
    "    st.subheader(\"Trend Chart\")\n",
    "    visual = data.get(\"visual_data\", {})\n",
    "    if visual and \"labels\" in visual and \"values\" in visual:\n",
    "        df = pd.DataFrame({\"Period\": visual[\"labels\"], \"Value\": visual[\"values\"]})\n",
    "        chart = px.line(df, x=\"Period\", y=\"Value\", title=\"Trend Over Time\", markers=True)\n",
    "        st.plotly_chart(chart, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No visual data provided.\")\n",
    "\n",
    "    # --- Section 5: Data Table ---\n",
    "    st.subheader(\"Comparative Table\")\n",
    "    table_data = data.get(\"table\", [])\n",
    "    if table_data:\n",
    "        df_table = pd.DataFrame(table_data)\n",
    "        st.dataframe(df_table, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No table data provided.\")\n",
    "\n",
    "    # --- Section 6: Sources ---\n",
    "    st.subheader(\"Sources\")\n",
    "    for src in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{src}]({src})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc50c2-a160-4d5d-ac68-8dfd67ff13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AI FINANCIAL RESEARCH ASSISTANT DASHBOARD\n",
    "# Integrating Steps 1–5 from previous builds\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: Base Perplexity Configuration\n",
    "# ----------------------------\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "# Response structure for consistent formatting\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Return responses ONLY in VALID JSON formatted exactly as follows:\n",
    "{\n",
    "  \"summary\": \"Brief text overview of recent market or economic findings.\",\n",
    "  \"key_insights\": [\"Insight 1\", \"Insight 2\", \"Insight 3\"],\n",
    "  \"metrics\": {\"GDP Growth (%)\": number, \"Inflation (%)\": number, \"Unemployment (%)\": number},\n",
    "  \"visual_data\": {\"labels\": [\"Q1\",\"Q2\",\"Q3\",\"Q4\"], \"values\": [2.3,2.6,3.1,2.9]},\n",
    "  \"table\": [{\"Country\": \"US\", \"GDP\": 25.5, \"Inflation\": 3.4}],\n",
    "  \"sources\": [\"https://www.imf.org\", \"https://www.reuters.com/markets\"],\n",
    "  \"confidence_score\": \"Provide a number from 0 to 100 indicating how confident you are in the accuracy of this response.\"\n",
    "\n",
    "}\n",
    "Do not include any text or explanation outside of JSON.\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    " #   \"You are restricted to topics about finance, business, markets, or economics.\\n\"\n",
    " #   \"Be honest and factual, and do not make anything up.\\n\"\n",
    " #   \"Format your answer exactly using the following JSON template:\\n\"\n",
    "\n",
    "    \"You are a financial research assistant that provides up‑to‑date, \"\n",
    "    \"fact‑checked insights strictly related to markets, finance, business, \"\n",
    "    \"stock market, macroeconomics and economics. Decline questions outside this scope.\\n\"\n",
    "    \"Format your answer exactly using the following JSON template:\\n\"\n",
    "    \n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: Real-Time Search Context\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "SCRAPING_DOG_URL = \"https://api.scrapingdog.com/scrape\"\n",
    "SCRAPING_DOG_KEY = os.getenv(\"SCRAPING_DOG_KEY\")\n",
    "\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
    "SERPAPI_URL = \"https://serpapi.com/search\"\n",
    "\n",
    "def get_live_context(search_query: str, num_results: int = 3) -> str:\n",
    "    \"\"\"Fetch live data snippets for the query to add context.\"\"\"\n",
    "    if not SERPAPI_KEY:\n",
    "        return \"Live web search disabled (SERPAPI_KEY missing).\"\n",
    "    try:\n",
    "        params = {\"q\": search_query, \"api_key\": SERPAPI_KEY, \"num\": num_results}\n",
    "        resp = requests.get(SERPAPI_URL, params=params, timeout=10)\n",
    "        data = resp.json().get(\"organic_results\", [])\n",
    "        snippets = [\n",
    "            f\"{r.get('title','')}: {r.get('snippet','')} ({r.get('link','')})\"\n",
    "            for r in data[:num_results]\n",
    "        ]\n",
    "        return \"\\n\".join(snippets)\n",
    "    except Exception as e:\n",
    "        return f\"[Context Warning] Failed to retrieve search data: {e}\"\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: Domain Filtering\n",
    "# ----------------------------\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "ALLOWED_TOPICS = [\n",
    "    \"finance\", \"economics\", \"markets\", \"trade\", \"business\",\n",
    "    \"macroeconomics\", \"investment\", \"monetary policy\"\n",
    "]\n",
    "\n",
    "def is_financial_query(query: str, threshold: float = 0.65) -> bool:\n",
    "    \"\"\"Check whether a query belongs to the financial domain.\"\"\"\n",
    "    result = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    label, score = result[\"labels\"][0], result[\"scores\"][0]\n",
    "    print(f\"[DomainCheck] Detected topic: {label} ({score:.2f})\")\n",
    "    return score >= threshold\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: Query Perplexity with Context and Formatting\n",
    "# ----------------------------\n",
    "def query_perplexity(prompt: str, query: str) -> str:\n",
    "    \"\"\"Send structured query to Perplexity with optional background.\"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    print(\"[Perplexity] Sending request...\")\n",
    "    response = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    response.raise_for_status()\n",
    "    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: Streamlit Rendering Logic\n",
    "# ----------------------------\n",
    "def render_dashboard(response_text):\n",
    "    \"\"\"Parse and render structured financial report from model output.\"\"\"\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        st.error(\"⚠️ Model output was not valid JSON format. Here's the raw response:\")\n",
    "        st.text(response_text)\n",
    "        return\n",
    "\n",
    "    # ---- Section 1: Summary\n",
    "    st.header(\"📈 Market Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary available.\"))\n",
    "\n",
    "    # ---- Section 2: Key Insights\n",
    "    st.subheader(\"Key Insights\")\n",
    "    insights = data.get(\"key_insights\", [])\n",
    "    if insights:\n",
    "        for item in insights:\n",
    "            st.markdown(f\"- {item}\")\n",
    "    else:\n",
    "        st.text(\"No notable insights found.\")\n",
    "\n",
    "    # ---- Section 3: Metrics Display\n",
    "    st.subheader(\"Current Economic Metrics\")\n",
    "    metrics = data.get(\"metrics\", {})\n",
    "    if metrics:\n",
    "        metric_cols = st.columns(len(metrics))\n",
    "        for i, (key, value) in enumerate(metrics.items()):\n",
    "            metric_cols[i].metric(key, value)\n",
    "    else:\n",
    "        st.info(\"Model did not produce metrics data.\")\n",
    "\n",
    "    # ---- Section 4: Trend Chart\n",
    "    st.subheader(\"Economic Trends\")\n",
    "    visual_data = data.get(\"visual_data\", {})\n",
    "    if visual_data and \"labels\" in visual_data and \"values\" in visual_data:\n",
    "        df_chart = pd.DataFrame({\n",
    "            \"Period\": visual_data[\"labels\"],\n",
    "            \"Value\": visual_data[\"values\"]\n",
    "        })\n",
    "        fig = px.line(df_chart, x=\"Period\", y=\"Value\", title=\"Quarterly Trend\", markers=True)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No visual data to plot.\")\n",
    "\n",
    "    # ---- Section 5: Comparative Table\n",
    "    st.subheader(\"Comparative Data Table\")\n",
    "    table_data = data.get(\"table\", [])\n",
    "    if isinstance(table_data, list) and table_data:\n",
    "        df_table = pd.DataFrame(table_data)\n",
    "        st.dataframe(df_table, use_container_width=True)\n",
    "    else:\n",
    "        st.warning(\"No tabular data found.\")\n",
    "\n",
    "    # ---- Section 6: Sources\n",
    "    st.subheader(\"Sources & References\")\n",
    "    for src in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{src}]({src})\")\n",
    "\n",
    "    # ---- Section 6: Confidence Score\n",
    "    st.subheader(\"Model Confidence Score\")\n",
    "    score = data.get(\"confidence_score\", None)\n",
    "    if score:\n",
    "        st.metric(\"Overall Confidence\", f\"{score}%\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# COMBINED MAIN APP\n",
    "# ----------------------------\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"AI Financial Research Assistant\", layout=\"wide\")\n",
    "    st.title(\"💹 AI‑Powered Financial Research Assistant Dashboard\")\n",
    "\n",
    "    query = st.text_input(\"Enter a finance, markets, or economics question:\")\n",
    "    enable_live = st.checkbox(\"Enable live market context search\", True)\n",
    "\n",
    "    if st.button(\"Generate Report\") and query:\n",
    "        with st.spinner(\"Fetching AI‑driven financial insights...\"):\n",
    "            # --- Step 3: Domain Filtering\n",
    "            if not is_financial_query(query):\n",
    "                st.error(\"Query denied: not a financial or economic topic.\")\n",
    "                return\n",
    "\n",
    "            # --- Step 2: Add Web Context if enabled\n",
    "            context = get_live_context(query) if enable_live else \"Live context not applied.\"\n",
    "\n",
    "            # --- Step 4: Get LLM Response\n",
    "            raw_output = query_perplexity(SYSTEM_PROMPT + \"\\n\" + context, query)\n",
    "\n",
    "            # --- Step 5: Structured Dashboard Rendering\n",
    "            render_dashboard(raw_output)\n",
    "\n",
    "# Entry point\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cb7eb7-07fa-4ace-806d-233ea8e19432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AI FINANCIAL RESEARCH ASSISTANT DASHBOARD v2\n",
    "# Includes Steps 1–6 (cross‑model validation)\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util  # Cross‑model validation\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: Base Perplexity Configuration\n",
    "# ----------------------------\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Return only valid JSON formatted as:\n",
    "{\n",
    "  \"summary\": \"Brief summary of findings.\",\n",
    "  \"key_insights\": [\"Insight 1\", \"Insight 2\"],\n",
    "  \"metrics\": {\"GDP Growth (%)\": number, \"Inflation (%)\": number, \"Unemployment (%)\": number},\n",
    "  \"visual_data\": {\"labels\": [\"Q1\",\"Q2\"], \"values\": [2.3,2.5]},\n",
    "  \"table\": [{\"Country\": \"US\", \"GDP\": 25.5, \"Inflation\": 3.4}],\n",
    "  \"sources\": [\"https://imf.org\", \"https://reuters.com\"],\n",
    "  \"confidence_score\": \"Provide a 0–100 confidence measure of your own answer\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You respond only to topics on finance, markets, or economics.\\n\"\n",
    "    \"Always output structured JSON in the exact format below:\\n\"\n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: Live Context Fetch (Optional)\n",
    "# ----------------------------\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
    "SERPAPI_URL = \"https://serpapi.com/search\"\n",
    "\n",
    "def get_live_context(query: str, num_results: int = 3) -> str:\n",
    "    \"\"\"Pull live search context from SerpAPI.\"\"\"\n",
    "    if not SERPAPI_KEY:\n",
    "        return \"Live context disabled (no SerpAPI key).\"\n",
    "    try:\n",
    "        params = {\"q\": query, \"api_key\": SERPAPI_KEY, \"num\": num_results}\n",
    "        resp = requests.get(SERPAPI_URL, params=params, timeout=10)\n",
    "        data = resp.json().get(\"organic_results\", [])\n",
    "        return \"\\n\".join(\n",
    "            [f\"{r.get('title','')}: {r.get('snippet','')} ({r.get('link','')})\"\n",
    "             for r in data[:num_results]]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"[Context fetch error] {e}\"\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: Domain Filtering\n",
    "# ----------------------------\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "ALLOWED_TOPICS = [\n",
    "    \"finance\", \"economics\", \"business\", \"markets\",\n",
    "    \"macroeconomics\", \"monetary policy\", \"banking\", \"investments\"\n",
    "]\n",
    "\n",
    "def is_finance_query(query: str, threshold: float = 0.65) -> bool:\n",
    "    result = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    label, score = result[\"labels\"][0], result[\"scores\"][0]\n",
    "    print(f\"[DomainCheck] {label} = {score:.2f}\")\n",
    "    return score >= threshold\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: Query Perplexity (Primary Model)\n",
    "# ----------------------------\n",
    "def query_perplexity(query: str, context: str = \"\") -> str:\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\\nContext:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: Secondary Model for Cross‑Validation\n",
    "# ----------------------------\n",
    "def query_secondary_model(query: str) -> str:\n",
    "    \"\"\"Simulate a second model (or call a different provider API).\"\"\"\n",
    "    # Replace with actual secondary model if available, e.g. Claude or GPT‑4\n",
    "    # For demonstration, use Perplexity Sonar Small to diversify output\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-small\",\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 800,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial assistant returning short analytical summaries.\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 6: Cross‑Model Validation\n",
    "# ----------------------------\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def cross_model_confidence(primary_text: str, secondary_text: str) -> float:\n",
    "    \"\"\"Compute cosine similarity between two model outputs.\"\"\"\n",
    "    emb1, emb2 = embedder.encode([primary_text, secondary_text])\n",
    "    sim = util.cos_sim(emb1, emb2).item()\n",
    "    final_score = round(sim * 100, 2)\n",
    "    print(f\"[Cross‑Model Confidence] {final_score}%\")\n",
    "    return final_score\n",
    "\n",
    "# ----------------------------\n",
    "# Dashboard Rendering Function\n",
    "# ----------------------------\n",
    "def render_dashboard(response_text: str, cross_conf: float):\n",
    "    \"\"\"Display AI results in rich layout.\"\"\"\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        st.error(\"Model output invalid. Raw response below:\")\n",
    "        st.text(response_text)\n",
    "        return\n",
    "\n",
    "    # ---- Top Section: Confidence\n",
    "    self_conf = float(data.get(\"confidence_score\", 0))\n",
    "    avg_conf = (self_conf + cross_conf) / 2 if cross_conf else self_conf\n",
    "    st.metric(\"Overall Confidence\", f\"{avg_conf:.1f} %\")\n",
    "\n",
    "    # ---- Summary Section\n",
    "    st.header(\"📈 Executive Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary.\"))\n",
    "\n",
    "    # ---- Insights\n",
    "    st.subheader(\"Key Insights\")\n",
    "    for i in data.get(\"key_insights\", []):\n",
    "        st.markdown(f\"- {i}\")\n",
    "\n",
    "    # ---- Metrics\n",
    "    st.subheader(\"Macroeconomic Indicators\")\n",
    "    metrics = data.get(\"metrics\", {})\n",
    "    if metrics:\n",
    "        cols = st.columns(len(metrics))\n",
    "        for i, (k, v) in enumerate(metrics.items()):\n",
    "            cols[i].metric(k, v)\n",
    "\n",
    "    # ---- Chart\n",
    "    st.subheader(\"Trends\")\n",
    "    vis = data.get(\"visual_data\", {})\n",
    "    if vis and \"labels\" in vis and \"values\" in vis:\n",
    "        df_plot = pd.DataFrame({\"Period\": vis[\"labels\"], \"Value\": vis[\"values\"]})\n",
    "        fig = px.line(df_plot, x=\"Period\", y=\"Value\", title=\"Trend Data\", markers=True)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # ---- Table\n",
    "    st.subheader(\"Comparative Table\")\n",
    "    table_data = data.get(\"table\", [])\n",
    "    if table_data:\n",
    "        st.dataframe(pd.DataFrame(table_data), use_container_width=True)\n",
    "\n",
    "    # ---- Sources\n",
    "    st.subheader(\"Sources & References\")\n",
    "    for s in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{s}]({s})\")\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN APP\n",
    "# ----------------------------\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"AI Financial Research Assistant v2\", layout=\"wide\")\n",
    "    st.title(\"💹 AI Financial Research Assistant — With Cross‑Model Validation\")\n",
    "\n",
    "    q = st.text_input(\"Enter a financial or market question:\")\n",
    "    live_context = st.checkbox(\"Enable Live Web Search\", True)\n",
    "\n",
    "    if st.button(\"Generate Report\") and q:\n",
    "        if not is_finance_query(q):\n",
    "            st.error(\"❌ Query not recognized as financial/economic.\")\n",
    "            return\n",
    "\n",
    "        context = get_live_context(q) if live_context else \"\"\n",
    "        with st.spinner(\"Getting analysis from primary LLM...\"):\n",
    "            res_primary = query_perplexity(q, context)\n",
    "\n",
    "        with st.spinner(\"Validating with secondary LLM...\"):\n",
    "            res_secondary = query_secondary_model(q)\n",
    "            cross_conf = cross_model_confidence(res_primary, res_secondary)\n",
    "\n",
    "        render_dashboard(res_primary, cross_conf)\n",
    "\n",
    "# Entry\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd650383-e3a5-410c-ba3e-bd4f2be83965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AI Financial Research Assistant Dashboard v3\n",
    "# Adds Cross-Model Fact/Numeric Accuracy Validation\n",
    "# ============================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: Base Perplexity Configuration\n",
    "# ----------------------------\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Return only valid JSON formatted as:\n",
    "{\n",
    "  \"summary\": \"Brief summary of findings.\",\n",
    "  \"key_insights\": [\"Insight 1\", \"Insight 2\"],\n",
    "  \"metrics\": {\"GDP Growth (%)\": number, \"Inflation (%)\": number, \"Unemployment (%)\": number},\n",
    "  \"visual_data\": {\"labels\": [\"Q1\",\"Q2\"], \"values\": [2.3,2.5]},\n",
    "  \"table\": [{\"Country\": \"US\", \"GDP\": 25.5, \"Inflation\": 3.4}],\n",
    "  \"sources\": [\"https://imf.org\", \"https://reuters.com\"],\n",
    "  \"confidence_score\": \"Provide a 0–100 confidence measure of your own answer\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You respond only to topics on finance, markets, or economics.\\n\"\n",
    "    \"Always output structured JSON in the exact format below:\\n\"\n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: Real-Time Search Context\n",
    "# ----------------------------\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
    "SERPAPI_URL = \"https://serpapi.com/search\"\n",
    "\n",
    "def get_live_context(query: str, num_results: int = 3) -> str:\n",
    "    if not SERPAPI_KEY:\n",
    "        return \"Live context disabled (no SerpAPI key).\"\n",
    "    try:\n",
    "        params = {\"q\": query, \"api_key\": SERPAPI_KEY, \"num\": num_results}\n",
    "        resp = requests.get(SERPAPI_URL, params=params, timeout=10)\n",
    "        data = resp.json().get(\"organic_results\", [])\n",
    "        return \"\\n\".join(\n",
    "            [f\"{r.get('title','')}: {r.get('snippet','')} ({r.get('link','')})\"\n",
    "             for r in data[:num_results]]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"[Context fetch error] {e}\"\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: Domain Filtering\n",
    "# ----------------------------\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "ALLOWED_TOPICS = [\n",
    "    \"finance\", \"economics\", \"business\", \"markets\",\n",
    "    \"macroeconomics\", \"monetary policy\", \"banking\", \"investments\"\n",
    "]\n",
    "\n",
    "def is_finance_query(query: str, threshold: float = 0.65) -> bool:\n",
    "    result = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    label, score = result[\"labels\"][0], result[\"scores\"][0]\n",
    "    print(f\"[DomainCheck] {label} = {score:.2f}\")\n",
    "    return score >= threshold\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: Query Perplexity (Primary Model)\n",
    "# ----------------------------\n",
    "def query_perplexity(query: str, context: str = \"\") -> str:\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\\nContext:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: Secondary Model for Cross-Validation\n",
    "# ----------------------------\n",
    "def query_secondary_model(query: str) -> str:\n",
    "    # For demo, uses Perplexity Sonar small variant; replace with actual alt LLM API if available\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-small\",\n",
    "        \"temperature\": 0,\n",
    "        \"max_tokens\": 800,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a financial assistant generating concise summaries.\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 6a: Semantic similarity calculation\n",
    "# ----------------------------\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def cross_model_confidence(primary_text: str, secondary_text: str) -> float:\n",
    "    emb1, emb2 = embedder.encode([primary_text, secondary_text])\n",
    "    sim = util.cos_sim(emb1, emb2).item()\n",
    "    final_score = round(sim * 100, 2)  # Convert to percentage\n",
    "    print(f\"[Cross-Model Semantic Similarity] {final_score}%\")\n",
    "    return final_score\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 6b: Numeric alignment score\n",
    "# ----------------------------\n",
    "def numeric_alignment_score(primary_json, secondary_json):\n",
    "    primary_metrics = primary_json.get(\"metrics\", {})\n",
    "    secondary_metrics = secondary_json.get(\"metrics\", {})\n",
    "    \n",
    "    if not primary_metrics or not secondary_metrics:\n",
    "        return None\n",
    "\n",
    "    total_diff = 0\n",
    "    count = 0\n",
    "    for key in primary_metrics:\n",
    "        if key in secondary_metrics:\n",
    "            try:\n",
    "                val1 = float(primary_metrics[key])\n",
    "                val2 = float(secondary_metrics[key])\n",
    "                if val1 == 0 and val2 == 0:\n",
    "                    diff = 0\n",
    "                else:\n",
    "                    diff = abs(val1 - val2) / max(abs(val1), abs(val2))\n",
    "                total_diff += diff\n",
    "                count += 1\n",
    "            except (ValueError, TypeError):\n",
    "                continue\n",
    "\n",
    "    if count == 0:\n",
    "        return None\n",
    "\n",
    "    avg_diff = total_diff / count\n",
    "    similarity_score = max(0.0, 1.0 - avg_diff) * 100\n",
    "    print(f\"[Numeric Alignment Score] {similarity_score}%\")\n",
    "    return round(similarity_score, 2)\n",
    "\n",
    "# ----------------------------\n",
    "# Dashboard Rendering\n",
    "# ----------------------------\n",
    "def render_dashboard(response_text: str, semantic_conf: float, numeric_conf: float):\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "    except json.JSONDecodeError:\n",
    "        st.error(\"Model output invalid JSON. Raw output:\")\n",
    "        st.text(response_text)\n",
    "        return\n",
    "\n",
    "    # Show combined confidence\n",
    "    self_conf = float(data.get(\"confidence_score\", 0))\n",
    "    combined_conf = (self_conf + semantic_conf) / 2\n",
    "    if numeric_conf is not None:\n",
    "        combined_conf = (combined_conf + numeric_conf) / 2\n",
    "\n",
    "    st.metric(\"Overall Confidence Score (%)\", f\"{combined_conf:.1f}\")\n",
    "\n",
    "    st.header(\"📈 Executive Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary provided.\"))\n",
    "\n",
    "    st.subheader(\"Key Insights\")\n",
    "    for insight in data.get(\"key_insights\", []):\n",
    "        st.markdown(f\"- {insight}\")\n",
    "\n",
    "    st.subheader(\"Macroeconomic Metrics\")\n",
    "    metrics = data.get(\"metrics\", {})\n",
    "    if metrics:\n",
    "        metric_cols = st.columns(len(metrics))\n",
    "        for i, (k, v) in enumerate(metrics.items()):\n",
    "            metric_cols[i].metric(k, v)\n",
    "\n",
    "    st.subheader(\"Trends Over Time\")\n",
    "    visual = data.get(\"visual_data\", {})\n",
    "    if \"labels\" in visual and \"values\" in visual:\n",
    "        df_plot = pd.DataFrame({\"Period\": visual[\"labels\"], \"Value\": visual[\"values\"]})\n",
    "        fig = px.line(df_plot, x=\"Period\", y=\"Value\", markers=True, title=\"Trend\")\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No visual data available.\")\n",
    "\n",
    "    st.subheader(\"Comparative Data Table\")\n",
    "    table_data = data.get(\"table\", [])\n",
    "    if table_data:\n",
    "        st.dataframe(pd.DataFrame(table_data), use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No tabular data present.\")\n",
    "\n",
    "    st.subheader(\"Sources\")\n",
    "    for source in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{source}]({source})\")\n",
    "\n",
    "# ----------------------------\n",
    "# Main App\n",
    "# ----------------------------\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"AI Financial Research Assistant v3\", layout=\"wide\")\n",
    "    st.title(\"💹 AI Financial Research Assistant Dashboard with Fact and Semantic Validation\")\n",
    "\n",
    "    user_query = st.text_input(\"Enter your market, finance, or economics question:\")\n",
    "    live_search_enabled = st.checkbox(\"Enable live context web search\", value=True)\n",
    "\n",
    "    if st.button(\"Get Report\") and user_query:\n",
    "        if not is_finance_query(user_query):\n",
    "            st.error(\"Query rejected: not classified as finance/economics domain.\")\n",
    "            return\n",
    "\n",
    "        context = get_live_context(user_query) if live_search_enabled else \"\"\n",
    "\n",
    "        with st.spinner(\"Querying primary LLM...\"):\n",
    "            primary_response = query_perplexity(user_query, context)\n",
    "\n",
    "        with st.spinner(\"Querying secondary LLM for validation...\"):\n",
    "            secondary_response = query_secondary_model(user_query)\n",
    "\n",
    "        semantic_score = cross_model_confidence(primary_response, secondary_response)\n",
    "\n",
    "        # Extract JSON for numeric comparison\n",
    "        try:\n",
    "            primary_json = json.loads(primary_response)\n",
    "            secondary_json = json.loads(secondary_response)\n",
    "            numeric_score = numeric_alignment_score(primary_json, secondary_json)\n",
    "        except Exception as e:\n",
    "            numeric_score = None\n",
    "            st.warning(f\"Numeric validation skipped due to parsing error: {e}\")\n",
    "\n",
    "        render_dashboard(primary_response, semantic_score, numeric_score)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055c4bb-a794-49d1-9d58-692fde6c39c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# AI Financial Research Assistant Dashboard v3\n",
    "# Adds Cross-Model Fact/Numeric Accuracy Validation + Self-Consistency Prompting\n",
    "# ============================================\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from collections import Counter\n",
    "\n",
    "# --- Config & API keys ---\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "SERPAPI_KEY = os.getenv(\"SERPAPI_KEY\")\n",
    "SERPAPI_URL = \"https://serpapi.com/search\"\n",
    "\n",
    "# --- Prompts ---\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Return ONLY valid JSON formatted exactly as:\n",
    "{\n",
    "  \"summary\": \"...\",\n",
    "  \"key_insights\": [\"...\", \"...\"],\n",
    "  \"metrics\": {\"GDP Growth (%)\": number, \"Inflation (%)\": number, \"Unemployment (%)\": number},\n",
    "  \"visual_data\": {\"labels\": [\"Q1\",\"Q2\"], \"values\": [2.3,2.5]},\n",
    "  \"table\": [{\"Country\": \"US\", \"GDP\": 25.5, \"Inflation\": 3.4}],\n",
    "  \"sources\": [\"https://imf.org\", \"https://reuters.com\"],\n",
    "  \"confidence_score\": \"Give a numeric confidence level 0-100 for your answer\"\n",
    "}\n",
    "\"\"\"\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You answer business, finance, markets, or economics queries ONLY.\\n\"\n",
    "    \"Format your response EXACTLY as the JSON template below:\\n\"\n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# --- Classifier and embedding for domain filtering and validation ---\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "ALLOWED_TOPICS = [\"finance\", \"economics\", \"business\", \"markets\", \"investment\"]\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# --- Helper functions ---\n",
    "\n",
    "def is_finance_query(query: str, threshold: float = 0.65) -> bool:\n",
    "    result = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    label, score = result[\"labels\"][0], result[\"scores\"][0]\n",
    "    return score >= threshold\n",
    "\n",
    "def get_live_context(query: str, num_results: int = 3) -> str:\n",
    "    if not SERPAPI_KEY:\n",
    "        return \"Live context disabled (no SerpAPI key).\"\n",
    "    try:\n",
    "        params = {\"q\": query, \"api_key\": SERPAPI_KEY, \"num\": num_results}\n",
    "        resp = requests.get(SERPAPI_URL, params=params, timeout=10)\n",
    "        data = resp.json().get(\"organic_results\", [])\n",
    "        return \"\\n\".join(\n",
    "            [f\"{r.get('title','')}: {r.get('snippet','')} ({r.get('link','')})\"\n",
    "             for r in data[:num_results]]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        return f\"Context fetch error: {e}\"\n",
    "\n",
    "def query_perplexity(query: str, context: str = \"\", temperature: float = 0) -> str:\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\\nContext:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def cross_model_confidence(text1: str, text2: str) -> float:\n",
    "    emb1, emb2 = embedder.encode([text1, text2])\n",
    "    sim = util.cos_sim(emb1, emb2).item()\n",
    "    return round(sim * 100, 2)\n",
    "\n",
    "def numeric_alignment_score(primary_json, secondary_json):\n",
    "    primary_metrics = primary_json.get(\"metrics\", {})\n",
    "    secondary_metrics = secondary_json.get(\"metrics\", {})\n",
    "    if not primary_metrics or not secondary_metrics:\n",
    "        return None\n",
    "    total_diff = 0\n",
    "    count = 0\n",
    "    for k in primary_metrics:\n",
    "        if k in secondary_metrics:\n",
    "            try:\n",
    "                v1 = float(primary_metrics[k])\n",
    "                v2 = float(secondary_metrics[k])\n",
    "                if v1 == 0 and v2 == 0:\n",
    "                    diff = 0\n",
    "                else:\n",
    "                    diff = abs(v1 - v2) / max(abs(v1), abs(v2))\n",
    "                total_diff += diff\n",
    "                count += 1\n",
    "            except Exception:\n",
    "                continue\n",
    "    if count == 0:\n",
    "        return None\n",
    "    avg_diff = total_diff / count\n",
    "    return round(max(0, 1 - avg_diff) * 100, 2)\n",
    "\n",
    "def majority_vote(responses):\n",
    "    cleaned_responses = [r.strip() for r in responses]\n",
    "    counts = Counter(cleaned_responses)\n",
    "    majority_response = counts.most_common(1)[0][0]\n",
    "    return majority_response\n",
    "\n",
    "def parse_confidence(response_text):\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "        return float(data.get(\"confidence_score\", 0))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def render_dashboard(response_text: str, semantic_conf: float, numeric_conf: float, final_conf: float):\n",
    "    try:\n",
    "        data = json.loads(response_text)\n",
    "    except Exception:\n",
    "        st.error(\"Invalid JSON output. Raw output:\")\n",
    "        st.text(response_text)\n",
    "        return\n",
    "\n",
    "    st.metric(\"Overall Confidence (%)\", f\"{final_conf:.1f}\")\n",
    "    st.header(\"📈 Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary.\"))\n",
    "\n",
    "    st.subheader(\"Key Insights\")\n",
    "    for insight in data.get(\"key_insights\", []):\n",
    "        st.markdown(f\"- {insight}\")\n",
    "\n",
    "    st.subheader(\"Metrics\")\n",
    "    metrics = data.get(\"metrics\", {})\n",
    "    if metrics:\n",
    "        cols = st.columns(len(metrics))\n",
    "        for i, (k, v) in enumerate(metrics.items()):\n",
    "            cols[i].metric(k, v)\n",
    "\n",
    "    st.subheader(\"Trends\")\n",
    "    vis = data.get(\"visual_data\", {})\n",
    "    if \"labels\" in vis and \"values\" in vis:\n",
    "        df = pd.DataFrame({\"Period\": vis[\"labels\"], \"Value\": vis[\"values\"]})\n",
    "        fig = px.line(df, x=\"Period\", y=\"Value\", title=\"Trend Over Time\", markers=True)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No visual data available.\")\n",
    "\n",
    "    st.subheader(\"Comparative Table\")\n",
    "    table = data.get(\"table\", [])\n",
    "    if table:\n",
    "        st.dataframe(pd.DataFrame(table), use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No table data available.\")\n",
    "\n",
    "    st.subheader(\"Sources\")\n",
    "    for src in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{src}]({src})\")\n",
    "\n",
    "\n",
    "### Main\n",
    "\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"AI Financial Assistant (Self-Consistency)\", layout=\"wide\")\n",
    "    st.title(\"💹 AI Financial Research Assistant with Self-Consistency\")\n",
    "\n",
    "    user_query = st.text_input(\"Enter finance or market related question:\")\n",
    "    enable_live_context = st.checkbox(\"Enable live context search\", True)\n",
    "    n_samples = st.slider(\"Number of model samples (self-consistency)\", 3, 10, 5)\n",
    "\n",
    "    if st.button(\"Generate Report\") and user_query:\n",
    "        if not is_finance_query(user_query):\n",
    "            st.error(\"Query rejected: not related to finance/economics.\")\n",
    "            return\n",
    "\n",
    "        context = get_live_context(user_query) if enable_live_context else \"\"\n",
    "\n",
    "        responses = []\n",
    "        confidences = []\n",
    "\n",
    "        with st.spinner(\"Generating multiple responses for self-consistency...\"):\n",
    "            for _ in range(n_samples):\n",
    "                resp = query_perplexity(user_query, context, temperature=0.7)  # sampling\n",
    "                responses.append(resp)\n",
    "                c = parse_confidence(resp)\n",
    "                confidences.append(c)\n",
    "\n",
    "        # Combine outputs\n",
    "        final_response = majority_vote(responses)\n",
    "        highest_confidence_resp = responses[confidences.index(max(confidences))]\n",
    "\n",
    "        # Use highest confidence response or majority vote (choose one)\n",
    "        chosen_response = highest_confidence_resp  # or final_response\n",
    "\n",
    "        # Validation with secondary model to get semantic and numeric scores\n",
    "        st.info(\"Validating response with secondary model for confidence...\")\n",
    "        secondary_resp = query_secondary_model(user_query)\n",
    "        semantic_conf = cross_model_confidence(chosen_response, secondary_resp)\n",
    "\n",
    "        try:\n",
    "            primary_json = json.loads(chosen_response)\n",
    "            secondary_json = json.loads(secondary_resp)\n",
    "            numeric_conf = numeric_alignment_score(primary_json, secondary_json)\n",
    "        except Exception:\n",
    "            numeric_conf = None\n",
    "\n",
    "        # Compute final combined confidence\n",
    "        self_conf = max(confidences) if confidences else 0\n",
    "        avg_confidence = (semantic_conf + self_conf) / 2\n",
    "        if numeric_conf is not None:\n",
    "            avg_confidence = (avg_confidence + numeric_conf) / 2\n",
    "\n",
    "        render_dashboard(chosen_response, semantic_conf, numeric_conf, avg_confidence)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b22873-e0e2-4af8-9dce-a0ee25fb272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AI FINANCIAL RESEARCH ASSISTANT DASHBOARD v4\n",
    "# Uses Perplexity Sonar (primary) + Gemini 2.0 Flash (secondary)\n",
    "# Adds self-consistency, numeric fact alignment, semantic validation\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from collections import Counter\n",
    "from openai import OpenAI\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: API KEYS AND CONFIG\n",
    "# ----------------------------\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "\n",
    "# Google Gemini uses OpenAI-compatible SDK\n",
    "gemini = OpenAI(\n",
    "    api_key=GEMINI_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Return ONLY valid JSON formatted as:\n",
    "{\n",
    "  \"summary\": \"Brief summary of findings.\",\n",
    "  \"key_insights\": [\"Insight 1\", \"Insight 2\"],\n",
    "  \"metrics\": {\"GDP Growth (%)\": number, \"Inflation (%)\": number, \"Unemployment (%)\": number},\n",
    "  \"visual_data\": {\"labels\": [\"Q1\",\"Q2\"], \"values\": [2.3,2.5]},\n",
    "  \"table\": [{\"Country\": \"US\", \"GDP\": 25.5, \"Inflation\": 3.4}],\n",
    "  \"sources\": [\"https://imf.org\", \"https://reuters.com\"],\n",
    "  \"confidence_score\": \"Provide a 0–100 confidence measure of your own answer\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You respond only to topics on business, finance, markets, or economics.\\n\"\n",
    "    \"Always output structured JSON in the exact format below:\\n\"\n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: Domain Classifier, Embedder\n",
    "# ----------------------------\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "ALLOWED_TOPICS = [\"finance\", \"economics\", \"markets\", \"business\", \"macroeconomics\"]\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: Helper Functions\n",
    "# ----------------------------\n",
    "def is_finance_query(query: str, threshold=0.65):\n",
    "    res = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    return res[\"scores\"][0] >= threshold\n",
    "\n",
    "def get_live_context(query: str):\n",
    "    return \"\"\n",
    "\n",
    "def query_perplexity(query: str, context: str = \"\", temperature: float = 0.7):\n",
    "    headers = {\"Authorization\": f\"Bearer {PERPLEXITY_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\\nContext:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: Gemini 2.0 Flash (Secondary Model)\n",
    "# ----------------------------\n",
    "def query_gemini_secondary(query: str, context: str = \"\") -> str:\n",
    "    completion = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"{SYSTEM_PROMPT}\\nContext:\\n{context}\"},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ],\n",
    "        temperature=0.3\n",
    "    )\n",
    "    return completion.choices[0].message.content[0].text if hasattr(completion.choices[0].message, \"content\") else completion.choices[0].message\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: Validation Functions\n",
    "# ----------------------------\n",
    "def cross_model_confidence(text1, text2):\n",
    "    emb1, emb2 = embedder.encode([text1, text2])\n",
    "    sim = util.cos_sim(emb1, emb2).item()\n",
    "    return round(sim * 100, 2)\n",
    "\n",
    "def numeric_alignment_score(p_json, s_json):\n",
    "    p_metrics, s_metrics = p_json.get(\"metrics\", {}), s_json.get(\"metrics\", {})\n",
    "    if not p_metrics or not s_metrics:\n",
    "        return None\n",
    "    diffs, count = 0, 0\n",
    "    for k in p_metrics:\n",
    "        if k in s_metrics:\n",
    "            try:\n",
    "                v1, v2 = float(p_metrics[k]), float(s_metrics[k])\n",
    "                if v1 == v2 == 0:\n",
    "                    d = 0\n",
    "                else:\n",
    "                    d = abs(v1 - v2) / max(abs(v1), abs(v2))\n",
    "                diffs += d\n",
    "                count += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "    if count == 0:\n",
    "        return None\n",
    "    score = (1 - (diffs / count)) * 100\n",
    "    return round(score, 2)\n",
    "\n",
    "def parse_conf(resp):\n",
    "    try:\n",
    "        js = json.loads(resp)\n",
    "        return float(js.get(\"confidence_score\", 0))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "def majority_vote(responses):\n",
    "    clean = [r.strip() for r in responses]\n",
    "    return Counter(clean).most_common(1)[0][0]\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 6: Dashboard Rendering\n",
    "# ----------------------------\n",
    "def render_dashboard(resp_text, sem_conf, num_conf, final_conf):\n",
    "    try:\n",
    "        data = json.loads(resp_text)\n",
    "    except Exception:\n",
    "        st.error(\"Invalid model JSON output. Showing raw text:\")\n",
    "        st.text(resp_text)\n",
    "        return\n",
    "\n",
    "    st.metric(\"Overall Confidence\", f\"{final_conf:.1f}%\")\n",
    "    st.header(\"📈 Executive Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary available.\"))\n",
    "\n",
    "    st.subheader(\"Key Insights\")\n",
    "    for insight in data.get(\"key_insights\", []):\n",
    "        st.markdown(f\"- {insight}\")\n",
    "\n",
    "    st.subheader(\"Metrics\")\n",
    "    met = data.get(\"metrics\", {})\n",
    "    if met:\n",
    "        cols = st.columns(len(met))\n",
    "        for i, (k, v) in enumerate(met.items()):\n",
    "            cols[i].metric(k, v)\n",
    "\n",
    "    st.subheader(\"Trends Over Time\")\n",
    "    vis = data.get(\"visual_data\", {})\n",
    "    if vis and \"labels\" in vis and \"values\" in vis:\n",
    "        df = pd.DataFrame({\"Period\": vis[\"labels\"], \"Value\": vis[\"values\"]})\n",
    "        fig = px.line(df, x=\"Period\", y=\"Value\", title=\"Trend\", markers=True)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    st.subheader(\"Data Table\")\n",
    "    tab = data.get(\"table\", [])\n",
    "    if tab:\n",
    "        st.dataframe(pd.DataFrame(tab), use_container_width=True)\n",
    "\n",
    "    st.subheader(\"Sources\")\n",
    "    for s in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{s}]({s})\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 7: Self-Consistency Loop and Main\n",
    "# ----------------------------\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Finance AI Assistant (Gemini Validation)\", layout=\"wide\")\n",
    "    st.title(\"💹 Financial AI Assistant – Perplexity x Gemini Self-Consistent Reasoning\")\n",
    "\n",
    "    query = st.text_input(\"Enter financial or economics question:\")\n",
    "    n_samples = st.slider(\"Number of self-consistency samples\", 3, 10, 5)\n",
    "\n",
    "    if st.button(\"Generate\"):\n",
    "        if not is_finance_query(query):\n",
    "            st.error(\"Query rejected (out of domain).\")\n",
    "            return\n",
    "\n",
    "        st.info(\"Generating multiple Perplexity Sonar responses...\")\n",
    "        responses, confidences = [], []\n",
    "        for _ in range(n_samples):\n",
    "            r = query_perplexity(query, temperature=0.7)\n",
    "            responses.append(r)\n",
    "            confidences.append(parse_conf(r))\n",
    "\n",
    "        best_resp = responses[confidences.index(max(confidences))]\n",
    "        majority_resp = majority_vote(responses)\n",
    "        chosen_response = best_resp\n",
    "\n",
    "        st.info(\"Validating via Gemini 2.0 Flash...\")\n",
    "        secondary_resp = query_gemini_secondary(query)\n",
    "        sem_conf = cross_model_confidence(chosen_response, secondary_resp)\n",
    "        try:\n",
    "            p_json, s_json = json.loads(chosen_response), json.loads(secondary_resp)\n",
    "            num_conf = numeric_alignment_score(p_json, s_json)\n",
    "        except Exception:\n",
    "            num_conf = None\n",
    "\n",
    "        base_conf = max(confidences)\n",
    "        final_conf = (base_conf + sem_conf + (num_conf or base_conf)) / (3 if num_conf else 2)\n",
    "        render_dashboard(chosen_response, sem_conf, num_conf, final_conf)\n",
    "\n",
    "# ----------------------------\n",
    "# Run Streamlit App\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdd1e7b-e93a-46e5-90d5-f242e5f3f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# AI FINANCIAL RESEARCH ASSISTANT – HYBRID VERIFICATION v5\n",
    "# Combines:\n",
    "#   - Self‑consistency reasoning (Perplexity Sonar)\n",
    "#   - Independent cross‑model validation (Gemini 2.0 Flash)\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "from openai import OpenAI\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: CONFIGURATION\n",
    "# ----------------------------\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "gemini = OpenAI(\n",
    "    api_key=GEMINI_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Return ONLY valid JSON formatted as:\n",
    "{\n",
    "  \"summary\": \"Brief summary of findings.\",\n",
    "  \"key_insights\": [\"Insight 1\", \"Insight 2\"],\n",
    "  \"metrics\": {\"GDP Growth (%)\": number, \"Inflation (%)\": number, \"Unemployment (%)\": number},\n",
    "  \"visual_data\": {\"labels\": [\"Q1\",\"Q2\"], \"values\": [2.3,2.5]},\n",
    "  \"table\": [{\"Country\": \"US\", \"GDP\": 25.5, \"Inflation\": 3.4}],\n",
    "  \"sources\": [\"https://imf.org\", \"https://reuters.com\"],\n",
    "  \"confidence_score\": \"Provide a 0–100 confidence measure of your own answer\"\n",
    "}\n",
    "\"\"\"\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You only answer topics in finance, economics, or markets.\\n\"\n",
    "    \"Output strictly in the JSON structure below:\\n\"\n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# Domain checking & embeddings for scoring\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "ALLOWED_TOPICS = [\"finance\", \"economics\", \"markets\", \"business\", \"macroeconomics\"]\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: CORE HELPERS\n",
    "# ----------------------------\n",
    "def is_finance_query(query: str, threshold=0.65):\n",
    "    r = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    return r[\"scores\"][0] >= threshold\n",
    "\n",
    "def query_perplexity(query: str, temperature=0.7):\n",
    "    headers = {\"Authorization\": f\"Bearer {PERPLEXITY_KEY}\",\n",
    "               \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def query_gemini(query: str):\n",
    "    comp = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=1000,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    result = comp.choices[0].message\n",
    "    if hasattr(result, \"content\") and isinstance(result.content, list):\n",
    "        return result.content[0].text\n",
    "    return result.content if hasattr(result, \"content\") else str(result)\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: SELF‑CONSISTENCY PROMPTING\n",
    "# ----------------------------\n",
    "def generate_self_consistent_responses(query, n=5):\n",
    "    st.info(f\"Generating {n} independent Perplexity analyst responses...\")\n",
    "    responses, scores = [], []\n",
    "    for _ in range(n):\n",
    "        r = query_perplexity(query, temperature=0.8)\n",
    "        responses.append(r)\n",
    "        scores.append(parse_confidence(r))\n",
    "    return responses, scores\n",
    "\n",
    "def majority_vote(responses):\n",
    "    cleaned = [r.strip() for r in responses]\n",
    "    vote = Counter(cleaned).most_common(1)[0][0]\n",
    "    return vote\n",
    "\n",
    "def parse_confidence(text):\n",
    "    try:\n",
    "        js = json.loads(text)\n",
    "        return float(js.get(\"confidence_score\", 0))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: HYBRID VALIDATION SCORING\n",
    "# ----------------------------\n",
    "def semantic_similarity_score(a, b):\n",
    "    v1, v2 = embedder.encode([a, b])\n",
    "    sim = util.cos_sim(v1, v2).item()\n",
    "    return round(sim * 100, 2)\n",
    "\n",
    "def numeric_alignment_score(j1, j2):\n",
    "    m1, m2 = j1.get(\"metrics\", {}), j2.get(\"metrics\", {})\n",
    "    if not m1 or not m2:\n",
    "        return None\n",
    "    total, count = 0, 0\n",
    "    for k in m1:\n",
    "        if k in m2:\n",
    "            try:\n",
    "                v1, v2 = float(m1[k]), float(m2[k])\n",
    "                if v1 == v2 == 0:\n",
    "                    d = 0\n",
    "                else:\n",
    "                    d = abs(v1 - v2) / max(abs(v1), abs(v2))\n",
    "                total += d\n",
    "                count += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "    if not count: return None\n",
    "    return round((1 - (total / count)) * 100, 2)\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: DASHBOARD RENDERER\n",
    "# ----------------------------\n",
    "def render_dashboard(response, final_conf, sem_conf, num_conf):\n",
    "    try:\n",
    "        data = json.loads(response)\n",
    "    except Exception:\n",
    "        st.error(\"Invalid JSON returned by model.\")\n",
    "        st.text(response)\n",
    "        return\n",
    "\n",
    "    st.metric(\"Overall Confidence (%)\", f\"{final_conf:.1f}\")\n",
    "    st.header(\"📊 Financial Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary.\"))\n",
    "\n",
    "    st.subheader(\"Key Insights\")\n",
    "    for i in data.get(\"key_insights\", []):\n",
    "        st.markdown(f\"- {i}\")\n",
    "\n",
    "    st.subheader(\"Metrics\")\n",
    "    mets = data.get(\"metrics\", {})\n",
    "    if mets:\n",
    "        cols = st.columns(len(mets))\n",
    "        for i, (k, v) in enumerate(mets.items()):\n",
    "            cols[i].metric(k, v)\n",
    "\n",
    "    st.subheader(\"Trend Visualization\")\n",
    "    vis = data.get(\"visual_data\", {})\n",
    "    if \"labels\" in vis and \"values\" in vis:\n",
    "        df = pd.DataFrame({\"Period\": vis[\"labels\"], \"Value\": vis[\"values\"]})\n",
    "        fig = px.line(df, x=\"Period\", y=\"Value\", title=\"Quarterly Trends\", markers=True)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    st.subheader(\"Data Table\")\n",
    "    tab = data.get(\"table\", [])\n",
    "    if tab:\n",
    "        st.dataframe(pd.DataFrame(tab), use_container_width=True)\n",
    "\n",
    "    st.subheader(\"Sources\")\n",
    "    for s in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{s}]({s})\")\n",
    "\n",
    "    st.write(f\"Semantic Similarity: {sem_conf:.2f}%\")\n",
    "    if num_conf is not None:\n",
    "        st.write(f\"Numeric Alignment: {num_conf:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 6: MAIN WORKFLOW\n",
    "# ----------------------------\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Hybrid Financial Research Assistant\", layout=\"wide\")\n",
    "    st.title(\"💹 Hybrid AI Financial Analyst – Self‑Consistency + Cross‑Model Verification\")\n",
    "\n",
    "    q = st.text_input(\"Enter your question about markets, finance, or economics:\")\n",
    "    n_paths = st.slider(\"Number of self‑consistent analysts (Perplexity)\", 3, 10, 5)\n",
    "\n",
    "    if st.button(\"Analyze\") and q:\n",
    "        if not is_finance_query(q):\n",
    "            st.error(\"Query not recognized as financial domain.\")\n",
    "            return\n",
    "\n",
    "        # 1. --- SELF-CONSISTENT REASONING ---\n",
    "        responses, scores = generate_self_consistent_responses(q, n_paths)\n",
    "        voted_response = majority_vote(responses)\n",
    "        best_response = responses[scores.index(max(scores))]\n",
    "        chosen_primary = best_response  # you may swap to voted_response if you prefer majority\n",
    "\n",
    "        # 2. --- INDEPENDENT SECONDARY VALIDATION (GEMINI) ---\n",
    "        st.info(\"Cross‑verifying via Gemini 2.0 Flash...\")\n",
    "        secondary_resp = query_gemini(q)\n",
    "\n",
    "        # 3. --- SCORING ---\n",
    "        sem_conf = semantic_similarity_score(chosen_primary, secondary_resp)\n",
    "        try:\n",
    "            j1, j2 = json.loads(chosen_primary), json.loads(secondary_resp)\n",
    "            num_conf = numeric_alignment_score(j1, j2)\n",
    "        except Exception:\n",
    "            num_conf = None\n",
    "\n",
    "        base_conf = max(scores)\n",
    "        final_conf = (base_conf + sem_conf + (num_conf if num_conf else base_conf)) / (3 if num_conf else 2)\n",
    "\n",
    "        # 4. --- DISPLAY ---\n",
    "        render_dashboard(chosen_primary, final_conf, sem_conf, num_conf)\n",
    "\n",
    "# ----------------------------\n",
    "# RUN STREAMLIT\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e633f78c-cc83-4f84-8739-211eeec325a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# AI FINANCIAL RESEARCH ASSISTANT – HYBRID VERIFICATION v5.1\n",
    "# Combines:\n",
    "#   - Self‑consistency reasoning (Perplexity Sonar)\n",
    "#   - Cross‑model validation (Gemini 2.0 Flash)\n",
    "# With bug fixes, timeouts, and validation guards.\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: CONFIGURATION\n",
    "# ----------------------------\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not PERPLEXITY_KEY or not GEMINI_KEY:\n",
    "    st.error(\"Missing API keys. Please set PERPLEXITY_API_KEY and GEMINI_API_KEY.\")\n",
    "    st.stop()\n",
    "\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "gemini = OpenAI(\n",
    "    api_key=GEMINI_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Return ONLY valid JSON formatted as:\n",
    "{\n",
    "  \"summary\": \"Brief summary of findings.\",\n",
    "  \"key_insights\": [\"Insight 1\", \"Insight 2\"],\n",
    "  \"metrics\": {\"GDP Growth (%)\": number, \"Inflation (%)\": number, \"Unemployment (%)\": number},\n",
    "  \"visual_data\": {\"labels\": [\"Q1\",\"Q2\"], \"values\": [2.3,2.5]},\n",
    "  \"table\": [{\"Country\": \"US\", \"GDP\": 25.5, \"Inflation\": 3.4}],\n",
    "  \"sources\": [\"https://imf.org\", \"https://reuters.com\"],\n",
    "  \"confidence_score\": \"Provide a 0–100 confidence measure of your own answer\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You only answer topics in finance, economics, or markets.\\n\"\n",
    "    \"Output strictly in the JSON structure below:\\n\"\n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# Domain classifier and embedder\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=-1)\n",
    "ALLOWED_TOPICS = [\"finance\", \"economics\", \"markets\", \"business\", \"macroeconomics\"]\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: CORE HELPERS\n",
    "# ----------------------------\n",
    "def is_finance_query(query: str, threshold=0.65):\n",
    "    r = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    return r[\"scores\"][0] >= threshold\n",
    "\n",
    "def query_perplexity(query: str, temperature=0.7):\n",
    "    headers = {\"Authorization\": f\"Bearer {PERPLEXITY_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def query_gemini(query: str):\n",
    "    comp = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=1000,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        msg = comp.choices[0].message\n",
    "        content = msg.content\n",
    "        if isinstance(content, list):\n",
    "            return \" \".join([part.text for part in content if hasattr(part, \"text\")])\n",
    "        return content if isinstance(content, str) else str(content)\n",
    "    except Exception as e:\n",
    "        print(f\"[Gemini Parsing Error] {e}\")\n",
    "        return json.dumps({\n",
    "            \"summary\": \"Gemini parsing error.\",\n",
    "            \"key_insights\": [],\n",
    "            \"metrics\": {},\n",
    "            \"visual_data\": {},\n",
    "            \"table\": [],\n",
    "            \"sources\": [],\n",
    "            \"confidence_score\": 0\n",
    "        })\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: SELF‑CONSISTENCY PROMPTING\n",
    "# ----------------------------\n",
    "def generate_self_consistent_responses(query, n=5):\n",
    "    st.info(f\"Generating {n} independent Perplexity analyst responses...\")\n",
    "    responses, scores = [], []\n",
    "    for _ in range(n):\n",
    "        try:\n",
    "            r = query_perplexity(query, temperature=0.8)\n",
    "            responses.append(r)\n",
    "            scores.append(parse_confidence(r))\n",
    "        except Exception as e:\n",
    "            st.warning(f\"Perplexity API error: {e}\")\n",
    "    return responses, scores\n",
    "\n",
    "def majority_vote(responses):\n",
    "    if not responses:\n",
    "        return \"\"\n",
    "    cleaned = [r.strip() for r in responses if r]\n",
    "    if not cleaned:\n",
    "        return \"\"\n",
    "    return Counter(cleaned).most_common(1)[0][0]\n",
    "\n",
    "def parse_confidence(text):\n",
    "    try:\n",
    "        js = json.loads(text)\n",
    "        return float(js.get(\"confidence_score\", 0))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: VALIDATION FUNCTIONS\n",
    "# ----------------------------\n",
    "def semantic_similarity_score(a, b):\n",
    "    try:\n",
    "        v1, v2 = embedder.encode([a, b])\n",
    "        sim = float(util.cos_sim(v1, v2))\n",
    "        return round(sim * 100, 2)\n",
    "    except Exception as e:\n",
    "        print(f\"Embedding error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def numeric_alignment_score(j1, j2):\n",
    "    m1, m2 = j1.get(\"metrics\", {}), j2.get(\"metrics\", {})\n",
    "    if not m1 or not m2:\n",
    "        return None\n",
    "    total, count = 0, 0\n",
    "    for k in m1:\n",
    "        if k in m2:\n",
    "            try:\n",
    "                v1, v2 = float(m1[k]), float(m2[k])\n",
    "                if v1 == v2 == 0:\n",
    "                    d = 0\n",
    "                else:\n",
    "                    d = abs(v1 - v2) / max(abs(v1), abs(v2))\n",
    "                total += d\n",
    "                count += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "    if count == 0:\n",
    "        return None\n",
    "    return round((1 - (total / count)) * 100, 2)\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: DASHBOARD RENDERER\n",
    "# ----------------------------\n",
    "def render_dashboard(response, final_conf, sem_conf, num_conf):\n",
    "    try:\n",
    "        data = json.loads(response)\n",
    "    except Exception:\n",
    "        st.error(\"Invalid JSON returned by model.\")\n",
    "        st.text(response)\n",
    "        return\n",
    "\n",
    "    st.metric(\"Overall Confidence (%)\", f\"{final_conf:.1f}\")\n",
    "    st.header(\"📊 Financial Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary.\"))\n",
    "\n",
    "    st.subheader(\"Key Insights\")\n",
    "    for i in data.get(\"key_insights\", []):\n",
    "        st.markdown(f\"- {i}\")\n",
    "\n",
    "    st.subheader(\"Metrics\")\n",
    "    mets = data.get(\"metrics\", {})\n",
    "    if mets:\n",
    "        cols = st.columns(len(mets))\n",
    "        for i, (k, v) in enumerate(mets.items()):\n",
    "            cols[i].metric(k, v)\n",
    "\n",
    "    st.subheader(\"Trend Visualization\")\n",
    "    vis = data.get(\"visual_data\", {})\n",
    "    if \"labels\" in vis and \"values\" in vis:\n",
    "        df = pd.DataFrame({\"Period\": vis[\"labels\"], \"Value\": vis[\"values\"]})\n",
    "        fig = px.line(df, x=\"Period\", y=\"Value\", title=\"Quarterly Trends\", markers=True)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No visual data available.\")\n",
    "\n",
    "    st.subheader(\"Data Table\")\n",
    "    tab = data.get(\"table\", [])\n",
    "    if tab:\n",
    "        st.dataframe(pd.DataFrame(tab), use_container_width=True)\n",
    "\n",
    "    st.subheader(\"Sources\")\n",
    "    for s in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{s}]({s})\")\n",
    "\n",
    "    st.write(f\"Semantic Similarity: {sem_conf:.2f}%\")\n",
    "    if num_conf is not None:\n",
    "        st.write(f\"Numeric Alignment: {num_conf:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 6: MAIN WORKFLOW\n",
    "# ----------------------------\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Hybrid Financial Research Assistant\", layout=\"wide\")\n",
    "    st.title(\"💹 Hybrid AI Financial Analyst – Self‑Consistency + Cross‑Model Verification\")\n",
    "\n",
    "    q = st.text_input(\"Enter your question about markets, finance, or economics:\")\n",
    "    n_paths = st.slider(\"Number of self‑consistent analysts (Perplexity)\", 3, 10, 5)\n",
    "\n",
    "    if st.button(\"Analyze\") and q:\n",
    "        if not is_finance_query(q):\n",
    "            st.error(\"Query not recognized as financial domain.\")\n",
    "            return\n",
    "\n",
    "        # --- Self‑Consistency Stage ---\n",
    "        responses, scores = generate_self_consistent_responses(q, n_paths)\n",
    "        voted_response = majority_vote(responses)\n",
    "        best_response = responses[scores.index(max(scores))] if scores else \"\"\n",
    "        chosen_primary = best_response or voted_response\n",
    "\n",
    "        if not chosen_primary:\n",
    "            st.error(\"Primary model failed to generate responses.\")\n",
    "            return\n",
    "\n",
    "        # --- Independent Validation Stage ---\n",
    "        st.info(\"Cross‑verifying via Gemini 2.0 Flash...\")\n",
    "        secondary_resp = query_gemini(q)\n",
    "\n",
    "        # --- Scoring ---\n",
    "        sem_conf = semantic_similarity_score(chosen_primary, secondary_resp)\n",
    "        try:\n",
    "            j1 = json.loads(chosen_primary)\n",
    "        except Exception:\n",
    "            j1 = {}\n",
    "        try:\n",
    "            j2 = json.loads(secondary_resp)\n",
    "        except Exception:\n",
    "            j2 = {}\n",
    "        num_conf = numeric_alignment_score(j1, j2)\n",
    "        base_conf = max(scores) if scores else 0\n",
    "\n",
    "        if num_conf is not None:\n",
    "            final_conf = np.mean([base_conf, sem_conf, num_conf])\n",
    "        else:\n",
    "            final_conf = np.mean([base_conf, sem_conf])\n",
    "\n",
    "        # --- Display ---\n",
    "        render_dashboard(chosen_primary, final_conf, sem_conf, num_conf)\n",
    "\n",
    "# ----------------------------\n",
    "# RUN STREAMLIT\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4cc72-95ee-4a6e-82a2-cf73fd90c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================================\n",
    "# AI FINANCIAL RESEARCH ASSISTANT – HYBRID VERIFICATION v6\n",
    "# Combines:\n",
    "#   - Self‑consistency reasoning (Perplexity Sonar)\n",
    "#   - Cross‑model validation (Gemini 2.0 Flash)\n",
    "# With bug fixes, timeouts, and validation guards.\n",
    "# Validated and fixed by Claude\n",
    "# =========================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import streamlit as st\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "from openai import OpenAI\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 1: CONFIGURATION\n",
    "# ----------------------------\n",
    "PERPLEXITY_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "GEMINI_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not PERPLEXITY_KEY or not GEMINI_KEY:\n",
    "    st.error(\"Missing API keys. Please set PERPLEXITY_API_KEY and GEMINI_API_KEY.\")\n",
    "    st.stop()\n",
    "\n",
    "PERPLEXITY_URL = \"https://api.perplexity.ai/chat/completions\"\n",
    "gemini = OpenAI(\n",
    "    api_key=GEMINI_KEY,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "RESPONSE_TEMPLATE = \"\"\"\n",
    "You are a financial research assistant. Return ONLY valid JSON formatted as:\n",
    "{\n",
    "  \"summary\": \"Brief summary of findings.\",\n",
    "  \"key_insights\": [\"Insight 1\", \"Insight 2\"],\n",
    "  \"metrics\": {\"GDP Growth (%)\": number, \"Inflation (%)\": number, \"Unemployment (%)\": number},\n",
    "  \"visual_data\": {\"labels\": [\"Q1\",\"Q2\"], \"values\": [2.3,2.5]},\n",
    "  \"table\": [{\"Country\": \"US\", \"GDP\": 25.5, \"Inflation\": 3.4}],\n",
    "  \"sources\": [\"https://imf.org\", \"https://reuters.com\"],\n",
    "  \"confidence_score\": \"Provide a 0–100 confidence measure of your own answer\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You only answer topics in finance, economics, or markets.\\n\"\n",
    "    \"Output strictly in the JSON structure below:\\n\"\n",
    "    f\"{RESPONSE_TEMPLATE}\"\n",
    ")\n",
    "\n",
    "# Domain classifier and embedder\n",
    "domain_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\", device=-1)\n",
    "ALLOWED_TOPICS = [\"finance\", \"economics\", \"markets\", \"business\", \"macroeconomics\"]\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 2: CORE HELPERS\n",
    "# ----------------------------\n",
    "def is_finance_query(query: str, threshold=0.65):\n",
    "    r = domain_classifier(query, ALLOWED_TOPICS)\n",
    "    return r[\"scores\"][0] >= threshold\n",
    "\n",
    "def query_perplexity(query: str, temperature=0.7):\n",
    "    headers = {\"Authorization\": f\"Bearer {PERPLEXITY_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": \"sonar-large\",\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    }\n",
    "    resp = requests.post(PERPLEXITY_URL, headers=headers, json=payload, timeout=30)\n",
    "    resp.raise_for_status()\n",
    "    return resp.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "def query_gemini(query: str):\n",
    "    comp = gemini.chat.completions.create(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        temperature=0.3,\n",
    "        max_tokens=1000,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": query}\n",
    "        ]\n",
    "    )\n",
    "    try:\n",
    "        msg = comp.choices[0].message\n",
    "        content = msg.content\n",
    "        if isinstance(content, list):\n",
    "            return \" \".join([part.text for part in content if hasattr(part, \"text\")])\n",
    "        return content if isinstance(content, str) else str(content)\n",
    "    except Exception as e:\n",
    "        print(f\"[Gemini Parsing Error] {e}\")\n",
    "        return json.dumps({\n",
    "            \"summary\": \"Gemini parsing error.\",\n",
    "            \"key_insights\": [],\n",
    "            \"metrics\": {},\n",
    "            \"visual_data\": {},\n",
    "            \"table\": [],\n",
    "            \"sources\": [],\n",
    "            \"confidence_score\": 0\n",
    "        })\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 3: SELF‑CONSISTENCY PROMPTING\n",
    "# ----------------------------\n",
    "def generate_self_consistent_responses(query, n=5):\n",
    "    st.info(f\"Generating {n} independent Perplexity analyst responses...\")\n",
    "    responses, scores = [], []\n",
    "    for _ in range(n):\n",
    "        try:\n",
    "            r = query_perplexity(query, temperature=0.8)\n",
    "            responses.append(r)\n",
    "            scores.append(parse_confidence(r))\n",
    "        except Exception as e:\n",
    "            st.warning(f\"Perplexity API error: {e}\")\n",
    "    return responses, scores\n",
    "\n",
    "def majority_vote(responses):\n",
    "    if not responses:\n",
    "        return \"\"\n",
    "    cleaned = [r.strip() for r in responses if r]\n",
    "    if not cleaned:\n",
    "        return \"\"\n",
    "    return Counter(cleaned).most_common(1)[0][0]\n",
    "\n",
    "def parse_confidence(text):\n",
    "    try:\n",
    "        js = json.loads(text)\n",
    "        return float(js.get(\"confidence_score\", 0))\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 4: VALIDATION FUNCTIONS\n",
    "# ----------------------------\n",
    "def semantic_similarity_score(a, b):\n",
    "    try:\n",
    "        v1, v2 = embedder.encode([a, b])\n",
    "        sim = float(util.cos_sim(v1, v2))\n",
    "        return round(sim * 100, 2)\n",
    "    except Exception as e:\n",
    "        print(f\"Embedding error: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "def numeric_alignment_score(j1, j2):\n",
    "    m1, m2 = j1.get(\"metrics\", {}), j2.get(\"metrics\", {})\n",
    "    if not m1 or not m2:\n",
    "        return None\n",
    "    total, count = 0, 0\n",
    "    for k in m1:\n",
    "        if k in m2:\n",
    "            try:\n",
    "                v1, v2 = float(m1[k]), float(m2[k])\n",
    "                if v1 == v2 == 0:\n",
    "                    d = 0\n",
    "                else:\n",
    "                    d = abs(v1 - v2) / max(abs(v1), abs(v2))\n",
    "                total += d\n",
    "                count += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "    if count == 0:\n",
    "        return None\n",
    "    return round((1 - (total / count)) * 100, 2)\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 5: DASHBOARD RENDERER\n",
    "# ----------------------------\n",
    "def render_dashboard(response, final_conf, sem_conf, num_conf):\n",
    "    try:\n",
    "        data = json.loads(response)\n",
    "    except Exception:\n",
    "        st.error(\"Invalid JSON returned by model.\")\n",
    "        st.text(response)\n",
    "        return\n",
    "\n",
    "    st.metric(\"Overall Confidence (%)\", f\"{final_conf:.1f}\")\n",
    "    st.header(\"📊 Financial Summary\")\n",
    "    st.write(data.get(\"summary\", \"No summary.\"))\n",
    "\n",
    "    st.subheader(\"Key Insights\")\n",
    "    for i in data.get(\"key_insights\", []):\n",
    "        st.markdown(f\"- {i}\")\n",
    "\n",
    "    st.subheader(\"Metrics\")\n",
    "    mets = data.get(\"metrics\", {})\n",
    "    if mets:\n",
    "        cols = st.columns(len(mets))\n",
    "        for i, (k, v) in enumerate(mets.items()):\n",
    "            cols[i].metric(k, v)\n",
    "\n",
    "    st.subheader(\"Trend Visualization\")\n",
    "    vis = data.get(\"visual_data\", {})\n",
    "    if \"labels\" in vis and \"values\" in vis:\n",
    "        df = pd.DataFrame({\"Period\": vis[\"labels\"], \"Value\": vis[\"values\"]})\n",
    "        fig = px.line(df, x=\"Period\", y=\"Value\", title=\"Quarterly Trends\", markers=True)\n",
    "        st.plotly_chart(fig, use_container_width=True)\n",
    "    else:\n",
    "        st.info(\"No visual data available.\")\n",
    "\n",
    "    st.subheader(\"Data Table\")\n",
    "    tab = data.get(\"table\", [])\n",
    "    if tab:\n",
    "        st.dataframe(pd.DataFrame(tab), use_container_width=True)\n",
    "\n",
    "    st.subheader(\"Sources\")\n",
    "    for s in data.get(\"sources\", []):\n",
    "        st.markdown(f\"- [{s}]({s})\")\n",
    "\n",
    "    st.write(f\"Semantic Similarity: {sem_conf:.2f}%\")\n",
    "    if num_conf is not None:\n",
    "        st.write(f\"Numeric Alignment: {num_conf:.2f}%\")\n",
    "\n",
    "# ----------------------------\n",
    "# STEP 6: MAIN WORKFLOW\n",
    "# ----------------------------\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Hybrid Financial Research Assistant\", layout=\"wide\")\n",
    "    st.title(\"💹 Hybrid AI Financial Analyst – Self‑Consistency + Cross‑Model Verification\")\n",
    "\n",
    "    q = st.text_input(\"Enter your question about markets, finance, or economics:\")\n",
    "    n_paths = st.slider(\"Number of self‑consistent analysts (Perplexity)\", 3, 10, 5)\n",
    "\n",
    "    if st.button(\"Analyze\") and q:\n",
    "        if not is_finance_query(q):\n",
    "            st.error(\"Query not recognized as financial domain.\")\n",
    "            return\n",
    "\n",
    "        # --- Self‑Consistency Stage ---\n",
    "        responses, scores = generate_self_consistent_responses(q, n_paths)\n",
    "        voted_response = majority_vote(responses)\n",
    "        best_response = responses[scores.index(max(scores))] if scores else \"\"\n",
    "        chosen_primary = best_response or voted_response\n",
    "\n",
    "        if not chosen_primary:\n",
    "            st.error(\"Primary model failed to generate responses.\")\n",
    "            return\n",
    "\n",
    "        # --- Independent Validation Stage ---\n",
    "        st.info(\"Cross‑verifying via Gemini 2.0 Flash...\")\n",
    "        secondary_resp = query_gemini(q)\n",
    "\n",
    "        # --- Scoring ---\n",
    "        sem_conf = semantic_similarity_score(chosen_primary, secondary_resp)\n",
    "        try:\n",
    "            j1 = json.loads(chosen_primary)\n",
    "        except Exception:\n",
    "            j1 = {}\n",
    "        try:\n",
    "            j2 = json.loads(secondary_resp)\n",
    "        except Exception:\n",
    "            j2 = {}\n",
    "        num_conf = numeric_alignment_score(j1, j2)\n",
    "        base_conf = max(scores) if scores else 0\n",
    "\n",
    "        if num_conf is not None:\n",
    "            final_conf = np.mean([base_conf, sem_conf, num_conf])\n",
    "        else:\n",
    "            final_conf = np.mean([base_conf, sem_conf])\n",
    "\n",
    "        # --- Display ---\n",
    "        render_dashboard(chosen_primary, final_conf, sem_conf, num_conf)\n",
    "\n",
    "# ----------------------------\n",
    "# RUN STREAMLIT\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
